import pandas as pd
from collections import defaultdict

# --- 1. Define stage columns ---
timestamp_columns = [
    'Backlog',
    'Ready for Development', 'In Development', 'Blocked',
    'Ready for UAT', 'In UAT', 'Ready for Deployment', 'Ready for Test',
    'In Test', 'Done', 'Cancelled'
]
progress_stages = [col for col in timestamp_columns if col not in ['Backlog', 'Done', 'Cancelled']]

# --- 2. Clean story points ---
df['Story Points'] = pd.to_numeric(df['Story Points'], errors='coerce')
df['Story Points'].fillna(0, inplace=True)

# --- 3. Convert timestamps to datetime ---
for col in timestamp_columns:
    if col in df.columns:
        df[col] = pd.to_datetime(df[col], errors='coerce')

# --- 4. Filter valid timeframe based on Backlog ---
start_date = pd.to_datetime("2024-12-30")
end_date = pd.to_datetime("2025-04-02")

df = df[
    df['Backlog'].notna() &
    (df['Backlog'] >= start_date) &
    (df['Backlog'] <= end_date) &
    ((df['Done'].isna()) | (df['Done'] <= end_date))
].copy()

# --- 5. Cap timestamps at Done/Cancelled ---
def cap_stage(row, col):
    end_time = row['Done'] if pd.notna(row['Done']) else row['Cancelled']
    if pd.notna(row[col]) and pd.notna(end_time):
        return min(row[col], end_time)
    return row[col]

for col in timestamp_columns:
    df[col] = df.apply(lambda row: cap_stage(row, col), axis=1)

# --- 6. First in-progress (for milestone metrics only) ---
def get_first_in_progress(row):
    stages = {col: row[col] for col in progress_stages if pd.notna(row[col])}
    return min(stages.values()) if stages else pd.NaT

df['First_In_Progress'] = df.apply(get_first_in_progress, axis=1)

# --- 7. Identify skipped workflows (Backlog â†’ Done or Cancelled only) ---
df['Skipped_Workflow'] = (
    df['Backlog'].notna() &
    (df['Done'].notna() | df['Cancelled'].notna()) &
    df['First_In_Progress'].isna()
)

# --- 8. Filter: real workflow tasks with 2+ timestamps ---
df_tracked = df[~df['Skipped_Workflow']].copy()
df_tracked = df_tracked[df_tracked[timestamp_columns].notna().sum(axis=1) >= 2].copy()

# --- 9. Milestone durations ---
df_tracked['Backlog_to_First_InProgress'] = (
    (df_tracked['First_In_Progress'] - df_tracked['Backlog']).dt.total_seconds() / 86400
).round(2).clip(lower=0.01)

df_tracked['InProgress_to_Done'] = (
    (df_tracked['Done'] - df_tracked['First_In_Progress']).dt.total_seconds() / 86400
).round(2).clip(lower=0.01)

df_tracked['Backlog_to_Done'] = (
    (df_tracked['Done'] - df_tracked['Backlog']).dt.total_seconds() / 86400
).round(2).clip(lower=0.01)

# --- 10. Build transition durations per task into a temporary dict-of-dicts ---
transition_data = {}

for idx, row in df_tracked.iterrows():
    stages = [(col, row[col]) for col in timestamp_columns if pd.notna(row[col])]
    stages = sorted(stages, key=lambda x: x[1])

    for i in range(len(stages) - 1):
        from_stage, start_time = stages[i]
        to_stage, end_time = stages[i + 1]

        duration = (end_time - start_time).total_seconds() / 86400
        if duration >= 0:
            transition_name = f"{from_stage} to {to_stage}"
            transition_data.setdefault(transition_name, {})[idx] = round(duration, 2)

# --- 11. Convert to transition DataFrame and merge it back ---
transition_df = pd.DataFrame.from_dict(transition_data)
df_tracked = df_tracked.join(transition_df)

# --- 12. Optional: Print skipped workflows count for transparency ---
print("Skipped Workflow Count:\n", df['Skipped_Workflow'].value_counts())
